# -*- coding: utf-8 -*-
"""NOCModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pkOywCoD3zXR3PbDUYuoy7-GTt6tMNFK
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from google.colab import drive
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
# Mount Google Drive
drive.mount('/content/drive')

# File paths
noc_file_path = '/content/drive/MyDrive/noc_stock_data.csv'


# Reading the data
noc_data = pd.read_csv(noc_file_path)


# This a function to help improve the Mean Error for better predictions
def add_technical_indicators(dataframe):
    dataframe['MA_50'] = dataframe['Close'].rolling(window=50).mean()
    dataframe['MA_200'] = dataframe['Close'].rolling(window=200).mean()

    # RSI
    delta = dataframe['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rsi = gain / loss
    dataframe['RSI'] = 100 - (100 / (1 + rsi))

    # Volume (already exists, just including for completeness)
    dataframe['Volume'] = dataframe['Volume']

    return dataframe

# Apply the function to the NOC data
noc_data = add_technical_indicators(noc_data)


# Drop any NaN values created by rolling windows
#noc_data.dropna(inplace=True)
#gd_data.dropna(inplace=True)

# Create lagged features
noc_data['Lag_1'] = noc_data['Close'].shift(1)


# Drop missing values
noc_data.dropna(inplace=True)


# Define feature and target variables for NOC
X_noc = noc_data[['Lag_1']]
y_noc = noc_data['Close']

# Define feature and target variables for GD


# Initialize and train the linear regression models for NOC and GD
model_noc = LinearRegression()
model_noc.fit(X_noc, y_noc)



# Make predictions for NOC
predictions_noc = model_noc.predict(X_noc)
mse_noc = mean_squared_error(y_noc, predictions_noc)
print(f"NOC Data - Mean Squared Error: {mse_noc}")

# File paths


# Assuming you've already loaded the data from the CSV file into 'noc_data'
drive.mount('/content/drive/')
noc_file_path = '/content/drive/MyDrive/noc_stock_data.csv'
noc_data = pd.read_csv(noc_file_path)

numeric_columns = ["Open", "High", "Low", "Close", "Volume"]
numeric_data = noc_data[numeric_columns]
# Calculate the Lag_1 values for gd_data
noc_data['Lag_1'] = noc_data['Close'].shift(1)

# Drop missing values
noc_data.dropna(inplace=True)

# Create a MinMaxScaler instance
scaler = MinMaxScaler(feature_range=(0, 1))

# Fit the scaler to your data
scaler.fit(numeric_data)

# Transform the data
input_data_scaled_noc = scaler.transform(numeric_data)

# Reshape the data
input_data_reshaped_noc = np.reshape(input_data_scaled_noc, (input_data_scaled_noc.shape[0], 1,input_data_scaled_noc.shape[1]))

# Print the reshaped data and its type
print(input_data_reshaped_noc)
print(type(input_data_reshaped_noc))

# Data scaling (LSTMs are sensitive to the scale of input data)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(X_noc)

# Reshape data for LSTM [samples, time steps, features]
X_lstm = np.reshape(scaled_data, (scaled_data.shape[0], 1, scaled_data.shape[1]))

# Build LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_lstm.shape[1], 1)))

model.add(LSTM(units=50))
model.add(Dense(1))

# Compile and fit the model
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(X_lstm, y_noc, epochs=100, batch_size=1, verbose=2)

# Start Date 01-30-2024
# End Date 04-30-2025
# Initialize the current lag value
last_lag_1 = noc_data['Lag_1'].iloc[-1]
current_lag = last_lag_1

# Store predictions
noc_future_predictions = []

# Predict for 15 months
for _ in range(456):
    # Create a DataFrame for the prediction input
    input_df = pd.DataFrame([current_lag], columns=['Lag_1'])

    # Predict the next value using the DataFrame
    next_prediction = model_noc.predict(input_df)[0]

    # Store the prediction
    noc_future_predictions.append(next_prediction)

    # Update the current lag value for the next prediction
    current_lag = next_prediction

print(noc_future_predictions)  # Print the last prediction
print(current_lag)             # This will be the same as the last prediction

"""Writing the predictions to a CSV file in my Google Drive"""

drive.mount('/content/drive')
# Convert predictions to a DataFrame
predictions_df = pd.DataFrame(noc_future_predictions, columns=['Predicted_Close'])

# Optional: If you want to add a date index to your predictions
start_date = pd.to_datetime("01-30-2024")
end_date = pd.to_datetime("04-24-2025")
dates = pd.date_range(start=start_date, periods=len(predictions_df), freq='D')
predictions_df.set_index(dates, inplace=True)

# Save to CSV
predictions_df.to_csv('/content/drive/MyDrive/predictions_noc_stock.csv')